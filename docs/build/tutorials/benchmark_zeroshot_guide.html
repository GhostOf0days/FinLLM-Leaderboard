

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Benchmarking LLama3.1 on Financial Tasks (zeroshot) &mdash; OpenFinLLM Leaderboard Documentation 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=e8ce10b2" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Tutorials" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            OpenFinLLM Leaderboard Documentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">OpenFinLLM Leaderboard Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Benchmarking LLama3.1 on Financial Tasks (zeroshot)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-structure">Dataset Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementation-steps">Implementation Steps</a></li>
<li class="toctree-l3"><a class="reference internal" href="#environment-setup">1. Environment Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#import-dependencies-setups">2. Import Dependencies &amp; Setups</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-initialization">3. Model Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#zero-shot-inference">4. Zero-Shot Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#evaluation">5. Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage">6. Usage</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenFinLLM Leaderboard Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Benchmarking LLama3.1 on Financial Tasks (zeroshot)</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Open-Finance-Lab/FinLLM-Leaderboard/blob/main/docs/source/tutorials/benchmark_zeroshot_guide.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="benchmarking-llama3-1-on-financial-tasks-zeroshot">
<h1>Benchmarking LLama3.1 on Financial Tasks (zeroshot)<a class="headerlink" href="#benchmarking-llama3-1-on-financial-tasks-zeroshot" title="Link to this heading"></a></h1>
<nav class="contents local" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#overview" id="id1">Overview</a></p></li>
<li><p><a class="reference internal" href="#dataset-structure" id="id2">Dataset Structure</a></p></li>
<li><p><a class="reference internal" href="#implementation-steps" id="id3">Implementation Steps</a></p></li>
<li><p><a class="reference internal" href="#environment-setup" id="id4">1. Environment Setup</a></p></li>
<li><p><a class="reference internal" href="#import-dependencies-setups" id="id5">2. Import Dependencies &amp; Setups</a></p></li>
<li><p><a class="reference internal" href="#model-initialization" id="id6">3. Model Initialization</a></p></li>
<li><p><a class="reference internal" href="#zero-shot-inference" id="id7">4. Zero-Shot Inference</a></p></li>
<li><p><a class="reference internal" href="#evaluation" id="id8">5. Evaluation</a></p></li>
<li><p><a class="reference internal" href="#usage" id="id9">6. Usage</a></p></li>
</ul>
</nav>
<section id="overview">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Overview</a><a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>This guide demonstrates a general methodology for benchmarking large language models (LLMs) on financial tasks using the <a class="reference external" href="https://huggingface.co/datasets/ChanceFocus/flare-fiqasa">FLARE-FIQASA dataset</a> and Meta’s <a class="reference external" href="https://huggingface.co/meta-llama/Llama-3.2-1B">Llama-3.2-1B model</a>. We will use the Zero-shot approach.</p>
</section>
<section id="dataset-structure">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Dataset Structure</a><a class="headerlink" href="#dataset-structure" title="Link to this heading"></a></h2>
<p>The FLARE-FIQASA dataset contains financial sentiment analysis examples with the following format:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;fiqasa0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;What is the sentiment of the following financial post: Positive, Negative, or Neutral? Text: Whats up with $LULU? Numbers looked good, not great, but good. I think conference call will instill confidence. Answer:&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;answer&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;neutral&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Whats up with $LULU? Numbers looked good, not great, but good. I think conference call will instill confidence.&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;choices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;negative&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;positive&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;neutral&quot;</span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;gold&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Key fields:
- <code class="docutils literal notranslate"><span class="pre">text</span></code>: Raw financial text
- <code class="docutils literal notranslate"><span class="pre">choices</span></code>: Possible labels
- <code class="docutils literal notranslate"><span class="pre">gold</span></code>: Correct answer index</p>
<p>Different datasets can have different structure depending on the author’s design. Typically dataset authors have their designed pipelines for models evaluating their dataset, so re producing the evaluation process may give different result depending on the implementation. For demonstrations, we will be implementing an evaluation pipeline from scratch to show the evaluation process.</p>
</section>
<section id="implementation-steps">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Implementation Steps</a><a class="headerlink" href="#implementation-steps" title="Link to this heading"></a></h2>
</section>
<section id="environment-setup">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">1. Environment Setup</a><a class="headerlink" href="#environment-setup" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="s1">&#39;accelerate&gt;=0.26.0&#39;</span> <span class="n">transformers</span> <span class="n">datasets</span> <span class="n">evaluate</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
</pre></div>
</div>
</section>
<section id="import-dependencies-setups">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">2. Import Dependencies &amp; Setups</a><a class="headerlink" href="#import-dependencies-setups" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">threading</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">TextIteratorStreamer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Model Variable</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Llama-3.2-1B&quot;</span>
<span class="n">DATASET_NAME</span> <span class="o">=</span> <span class="s2">&quot;ChanceFocus/flare-fiqasa&quot;</span>
<span class="n">ACCESS_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;hf_token_here&quot;</span>
<span class="c1"># You must get your own Huggingface token from https://huggingface.co/settings/tokens</span>
<span class="c1"># You will also need to request model access for each model you used on the huggingface model repository</span>
<span class="c1"># Request access to https://huggingface.co/meta-llama/Llama-3.2-1B</span>
</pre></div>
</div>
</section>
<section id="model-initialization">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">3. Model Initialization</a><a class="headerlink" href="#model-initialization" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading model...&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">MODEL_NAME</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">token</span><span class="o">=</span><span class="n">ACCESS_TOKEN</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading tokenizer...&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="zero-shot-inference">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">4. Zero-Shot Inference</a><a class="headerlink" href="#zero-shot-inference" title="Link to this heading"></a></h2>
<p>Zero-shot: Testing without providing examples. Asking LLM your question directly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># A example text we will send to the LLM</span>
<span class="k">def</span><span class="w"> </span><span class="nf">zero_shot_prompt</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Analyze the sentiment of this financial text:</span>
<span class="s2">Text: </span><span class="si">{</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="si">}</span>
<span class="s2">Options: </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;choices&#39;</span><span class="p">])</span><span class="si">}</span>
<span class="s2">Answer:&quot;&quot;&quot;</span>
</pre></div>
</div>
</section>
<section id="evaluation">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">5. Evaluation</a><a class="headerlink" href="#evaluation" title="Link to this heading"></a></h2>
<p>We use accuracy as our evaluation metric. There are two strategies for computing accuracy in this context:</p>
<p>Exact Match: The model’s generated answer must exactly match the gold label. This means the extracted sentiment (e.g., positive, negative, neutral) must be identical to the expected label without any variation. If the output deviates in any way, even if it conveys the same sentiment, it is considered incorrect.</p>
<p>Partial Match: Instead of requiring an exact match, this approach checks whether the extracted sentiment is present within the model’s response. It allows for some flexibility, ensuring that as long as the generated text contains the correct sentiment label, it is considered a correct prediction.</p>
<p>In our evaluation, we use partial match, as it accommodates variations in the model’s response while still capturing the intended sentiment classification.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_with_progress</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="c1"># Create a streamer object to stream the generated text</span>
    <span class="n">streamer</span> <span class="o">=</span> <span class="n">TextIteratorStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">skip_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Using threadings to parallel generating texts.</span>
    <span class="n">generation_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
        <span class="n">streamer</span><span class="o">=</span><span class="n">streamer</span>
    <span class="p">)</span>
    <span class="n">thread</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">generation_kwargs</span><span class="p">)</span>
    <span class="n">thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="n">generated_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Generating text&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="n">dynamic_ncols</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">gen_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">new_text</span> <span class="ow">in</span> <span class="n">streamer</span><span class="p">:</span>
            <span class="n">generated_text</span> <span class="o">+=</span> <span class="n">new_text</span>
            <span class="n">gen_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">thread</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">generated_text</span>


<span class="k">def</span><span class="w"> </span><span class="nf">extract_answer_section</span><span class="p">(</span><span class="n">response</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Our example input looks like this</span>
<span class="sd">        Analyze the sentiment of this financial text:</span>
<span class="sd">        Text: Legal &amp; General share price: Finance chief to step down</span>
<span class="sd">        Options: negative, positive, neutral</span>
<span class="sd">        Answer:</span>
<span class="sd">    Given LLM is generating word by word after the initial input. The result output will look like (For llama3.1. Can vary depending on models)</span>
<span class="sd">        Analyze the sentiment of this financial text:</span>
<span class="sd">        Text: Legal &amp; General share price: Finance chief to step down</span>
<span class="sd">        Options: negative, positive, neutral</span>
<span class="sd">        Answer: neutral</span>
<span class="sd">        Explanation: xxx</span>

<span class="sd">    Here we extract labels after &quot;Answer:&quot; and before，&quot;Explanation:&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lower_response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">answer_idx</span> <span class="o">=</span> <span class="n">lower_response</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;answer:&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">answer_idx</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>
    <span class="c1"># After &quot;Answer:&quot;</span>
    <span class="n">answer_section</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="n">answer_idx</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;answer:&quot;</span><span class="p">):]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="c1"># Before &quot;Explanation:&quot;</span>
    <span class="n">explanation_idx</span> <span class="o">=</span> <span class="n">answer_section</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;explanation:&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">explanation_idx</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">answer_section</span> <span class="o">=</span> <span class="n">answer_section</span><span class="p">[:</span><span class="n">explanation_idx</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">answer_section</span>


<span class="k">def</span><span class="w"> </span><span class="nf">extract_sentiment</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">choices</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract sentiment tags from generated text:</span>
<span class="sd">        1. First extract the answer part after &quot;Answer:&quot;;</span>
<span class="sd">        2. Check whether the answer part contains candidate sentiment words (whole word matching, ignoring case);</span>
<span class="sd">        3. If there is no match, return None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">answer_section</span> <span class="o">=</span> <span class="n">extract_answer_section</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">answer_section</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">choice</span> <span class="ow">in</span> <span class="n">choices</span><span class="p">:</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;\b&#39;</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">choice</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">&#39;\b&#39;</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">answer_section</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">choice</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="k">def</span><span class="w"> </span><span class="nf">label_to_int</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      &quot;negative&quot; -&gt; 0</span>
<span class="sd">      &quot;positive&quot; -&gt; 1</span>
<span class="sd">      &quot;neutral&quot;  -&gt; 2</span>
<span class="sd">    None -&gt; -1。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;negative&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;positive&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;neutral&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">label</span>
    <span class="k">return</span> <span class="n">mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># Partial match. Print gold and generated results</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_model</span><span class="p">(</span><span class="n">dataset_split</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">):</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">references</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Progress bar</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span>
        <span class="n">total</span><span class="o">=</span><span class="n">num_examples</span><span class="p">,</span>
        <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Evaluating samples&quot;</span><span class="p">,</span>
        <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">,</span>
        <span class="n">dynamic_ncols</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ex</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset_split</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">))):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">zero_shot_prompt</span><span class="p">(</span><span class="n">ex</span><span class="p">),</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">output_scores</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_dict_in_generate</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="c1"># Decode the generated token id list into text</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s2">&quot;sequences&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Use partial matching to extract sentiment labels in generated answers (only partial matching from Answer)</span>
        <span class="n">extracted</span> <span class="o">=</span> <span class="n">extract_sentiment</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">ex</span><span class="p">[</span><span class="s1">&#39;choices&#39;</span><span class="p">])</span>
        <span class="n">pred_label</span> <span class="o">=</span> <span class="n">extracted</span> <span class="k">if</span> <span class="n">extracted</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;unknown&quot;</span>

        <span class="c1"># Print the gold answer and the full text generated for the current sample</span>
        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Gold answer: </span><span class="si">{</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (index: </span><span class="si">{</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;gold&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated text: </span><span class="se">\n\t</span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Extracted LLM answer: </span><span class="si">{</span><span class="n">pred_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

        <span class="c1"># Convert predictions and gold labels to integers</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_to_int</span><span class="p">(</span><span class="n">pred_label</span><span class="p">))</span>
        <span class="n">references</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_to_int</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;gold&#39;</span><span class="p">]))</span>

        <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">current_acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">)[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
        <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s2">&quot;current_acc&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">current_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">})</span>

    <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="usage">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">6. Usage</a><a class="headerlink" href="#usage" title="Link to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">DATASET_NAME</span><span class="p">)</span>

<span class="n">example</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">zero_prompt</span> <span class="o">=</span> <span class="n">zero_shot_prompt</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Running zero-shot inference:&quot;</span><span class="p">)</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">generate_with_progress</span><span class="p">(</span><span class="n">zero_prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">extracted_label</span> <span class="o">=</span> <span class="n">extract_sentiment</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;choices&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Zero-Shot Extracted Label: </span><span class="si">{</span><span class="n">extracted_label</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">extracted_label</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;unknown&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Starting evaluation:&quot;</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">num_examples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Final Accuracy: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, OpenFinLLM Leaderboard.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>